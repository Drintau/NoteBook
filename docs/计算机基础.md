# 计算机基础

## 位，字节，字符，字符集，编码

位（bit）：数据存储的最小单位。每个二进制数字0或者1就是1个位。

字节（Byte）：8位二进制数构成1个字节，即：1 Byte(字节) = 8 bit(位)。

字符：a、H、中、5、+、%……均表示一个字符。  
ASCII 编码下，没有汉字字符，一个英文字符占用 1 个字节。  
UTF-8 编码下，一个汉字字符占用 3 - 4 个字节，一个英文字符占用 1 个字节。  
GBK 编码下，一个汉字字符占用 2 个字节。

字符集：多个字符的集合，汉字、字母、符号会被收录其中。  
常见字符集：ASCII 字符集、GBK 字符集、GB2312 字符集、Unicode 字符集等。

字符编码：是对字符集中字符进行编码；规定每个“字符”分别用一个字节还是多个字节存储，用哪些字节来存储。  
经常提到的ASCII编码、UTF-8编码等均指对应的字符集编码。

## ASCII，Unicode，UTF-8

ASCII 码使用7位或8位二进制数组合来表示128或256种可能的字符。  
标准 ASCII 码一共规定了128个字符的编码，只占用了一个字节的后面7位，最前面的一位统一规定为0。后128个称为扩展 ASCII 码。

世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。  
如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是 Unicode，是一种所有符号的编码。  
Unicode 现在的规模可以容纳100多万个符号。

需要注意的是，Unicode 只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。  
比如，汉字严的 Unicode 是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。

这里就有两个严重的问题：
1. 如何才能区别 Unicode 和 ASCII ？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？
2. 英文字母只用一个字节表示就够了，如果 Unicode 统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费。

于是，出现了 Unicode 的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示 Unicode。

UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。  
UTF-8 的编码规则很简单，只有两条：
1. 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。
2. 对于n字节的符号（n > 1），第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。

UTF-8 编码把一个 Unicode 字符根据不同的数字大小编码成1-4个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4个字节。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间。  
UTF-8 编码还有一个额外的好处，就是ASCII编码实际上可以被看成是UTF-8编码的一部分，所以，大量只支持ASCII编码的历史遗留软件可以在UTF-8编码下继续工作。

Unicode 统一编码，解决乱码问题。UTF-8 节约 Unicode 的存储空间，兼容 ASCII。

## Base64编码

Base64 是一种基于64个可见字符来表示二进制数据的表示方法。  
64个可见字符：A-Z，a-z，0-9，+，/。  
编码规则：将3个8位字节(3×8=24位)编码成4个6位的字节(4×6=24位)，之后在每个6位字节前面，补充两个0，形成4个8位字节。末尾不够4个字节则补充'='号。  
一个 Base64 字符是8个bit位，但是有效部分只有右边的6个bit，左边两个bit永远是0。
